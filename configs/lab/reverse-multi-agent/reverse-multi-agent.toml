max_steps = 20
seq_len = 2048

[model]
name = "PrimeIntellect/Qwen3-0.6B-Reverse-Text-SFT"

[wandb]
project = "reverse-multi-agent"
name = "reverse-multi-agent"

[trainer.model]
impl = "auto"

[trainer.model.ac]
freq = 1

[trainer.model.lora]
rank = 32
alpha = 64

[trainer.optim]
lr = 3e-6

# Multi-agent training: both agents share lora_id=0
[trainer]
max_concurrent_runs = 1

[orchestrator]
batch_size = 128
rollouts_per_example = 16

[orchestrator.sampling]
max_tokens = 128

[[orchestrator.env]]
id = "wambosec/reverse-multi-agent"
name = "reverse-multi-agent"

[ckpt]

[inference]
